2025-04-17 14:14:50 INFO Saving logs to /home/dasoumao/LLMBox/logs/deepseek-r1-mt_bench-0shot-2025_04_17-14_14_50.log
2025-04-17 14:14:50 INFO LLMBox revision: Not a git repository
2025-04-17 14:14:50 INFO Run commands (pid=70584):  /home/dasoumao/miniconda3/envs/nlp/bin/python inference.py -m deepseek-r1 -d mt_bench --openai_api_key 'sk-Cdaw6***************************************bOYt' --model_backend openai --hf_mirror --batch_size 1
2025-04-17 14:14:50 INFO EvaluationArguments(seed=2023, logging_dir='logs', log_level='info', evaluation_results_dir='evaluation_results', log_results=True, dataset_threading=True, dataloader_workers=0)
2025-04-17 14:14:51 INFO Loading OpenAI API model `deepseek-r1`.
2025-04-17 14:14:51 INFO Trying to load OpenAI model with OPENAI_BASE_URL='https://nekoapi.com/v1'
2025-04-17 14:14:53 INFO Failed when trying to get_dataset_config_names(/home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts/mt_bench_prompts.py): Couldn't find a dataset script at /home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts/mt_bench_prompts.py
2025-04-17 14:14:53 INFO Loading dataset `mt_bench`
2025-04-17 14:14:53 INFO ModelArguments(model_name_or_path='deepseek-r1', model_type='chat', model_backend='openai', openai_api_key='sk-Cdaw6***************************************bOYt', api_endpoint='chat/completions', tokenizer_name_or_path='cl100k_base', cuda_visible_devices='', torch_dtype='auto')
2025-04-17 14:14:53 INFO DatasetArguments(dataset_names=['mt_bench'], batch_size=1, dataset_path='/home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts', num_shots=0, max_example_tokens=1024, sample_num=1, max_evaluation_instances=0, hf_mirror=True, hfd_cache_path='~/.cache/huggingface/datasets')
2025-04-17 14:14:53 INFO Loading raw dataset `mt_bench` from local path `/home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts` with evaluation set `train`
2025-04-17 14:14:58 INFO Evaluation data with 80 instances:
{'question_1': 'Compose an engaging travel blog post about a recent trip to '
               'Hawaii, highlighting cultural experiences and must-see '
               'attractions.',
 'question_2': 'Rewrite your previous response. Start every sentence with the '
               'letter A.'}
2025-04-17 14:14:58 INFO Formatted evaluation instance 0
('Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural '
 'experiences and must-see attractions.')
2025-04-17 14:14:58 INFO Evaluating generation on mt_bench (model_attr={'model_type': 'chat', 'model_backend': 'openai', 'multi_turn': True}, generation_kwargs={'max_tokens': 4096, 'seed': 2023}, num_shots=0, len=80, num_instances=80, use_cache=False)
2025-04-17 14:16:20 INFO Finished at 0 instances after 00:00.
2025-04-17 14:16:20 WARNING Error occurred during evaluation. You can continue evaluation by loading the checkpoint: --continue_from evaluation_results/deepseek-r1-mt_bench-0shot-2025_04_17-14_14_50.json
2025-04-17 14:16:20 ERROR [evaluate] KeyboardInterrupt: 

Traceback (most recent call last):
  File "/home/dasoumao/LLMBox/utilization/utils/catch_error.py", line 40, in wrapper
    return func(*args, **kwargs)
  File "/home/dasoumao/LLMBox/utilization/evaluator.py", line 111, in evaluate
    batch_results = call_model(batch)
  File "/home/dasoumao/LLMBox/utilization/model/model_utils/batch_sampler.py", line 209, in call_model
    return self._forward_call(*args, **kwargs)  # type: ignore
  File "/home/dasoumao/LLMBox/utilization/model/model.py", line 305, in generation
    multi_turn_results = self.request(
  File "/home/dasoumao/LLMBox/utilization/model/model.py", line 353, in request
    response = self._chat_completions(
  File "/home/dasoumao/LLMBox/utilization/model/model.py", line 214, in wrapper
    results = func(*args, **kwargs)
  File "/home/dasoumao/LLMBox/utilization/model/openai_model.py", line 50, in _chat_completions
    results = openai.chat.completions.create(messages=messages, model=model, **kwargs)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 929, in create
    return self._post(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 1276, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 949, in request
    return self._request(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _request
    return self._retry_request(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 1091, in _retry_request
    return self._request(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 989, in _request
    response = self._client.send(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_sync/http_proxy.py", line 343, in handle_request
    return self._connection.handle_request(request)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/ssl.py", line 1292, in recv
    return self.read(buflen)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/ssl.py", line 1165, in read
    return self._sslobj.read(len)
KeyboardInterrupt

