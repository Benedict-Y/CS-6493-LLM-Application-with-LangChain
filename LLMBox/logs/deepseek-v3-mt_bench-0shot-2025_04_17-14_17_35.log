2025-04-17 14:17:35 INFO Saving logs to /home/dasoumao/LLMBox/logs/deepseek-v3-mt_bench-0shot-2025_04_17-14_17_35.log
2025-04-17 14:17:35 INFO LLMBox revision: Not a git repository
2025-04-17 14:17:35 INFO Run commands (pid=71842):  /home/dasoumao/miniconda3/envs/nlp/bin/python inference.py -m deepseek-v3 -d mt_bench --openai_api_key 'sk-Cdaw6***************************************bOYt' --model_backend openai --hf_mirror --batch_size 1
2025-04-17 14:17:35 INFO EvaluationArguments(seed=2023, logging_dir='logs', log_level='info', evaluation_results_dir='evaluation_results', log_results=True, dataset_threading=True, dataloader_workers=0)
2025-04-17 14:17:38 INFO Loading OpenAI API model `deepseek-v3`.
2025-04-17 14:17:38 INFO Trying to load OpenAI model with OPENAI_BASE_URL='https://nekoapi.com/v1'
2025-04-17 14:17:40 INFO Failed when trying to get_dataset_config_names(/home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts/mt_bench_prompts.py): Couldn't find a dataset script at /home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts/mt_bench_prompts.py
2025-04-17 14:17:40 INFO Loading dataset `mt_bench`
2025-04-17 14:17:40 INFO ModelArguments(model_name_or_path='deepseek-v3', model_type='chat', model_backend='openai', openai_api_key='sk-Cdaw6***************************************bOYt', api_endpoint='chat/completions', tokenizer_name_or_path='cl100k_base', cuda_visible_devices='', torch_dtype='auto')
2025-04-17 14:17:40 INFO DatasetArguments(dataset_names=['mt_bench'], batch_size=1, dataset_path='/home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts', num_shots=0, max_example_tokens=1024, sample_num=1, max_evaluation_instances=0, hf_mirror=True, hfd_cache_path='~/.cache/huggingface/datasets')
2025-04-17 14:17:40 INFO Loading raw dataset `mt_bench` from local path `/home/dasoumao/.cache/huggingface/datasets/datasets--HuggingFaceH4--mt_bench_prompts` with evaluation set `train`
2025-04-17 14:17:45 INFO Evaluation data with 80 instances:
{'question_1': 'Compose an engaging travel blog post about a recent trip to '
               'Hawaii, highlighting cultural experiences and must-see '
               'attractions.',
 'question_2': 'Rewrite your previous response. Start every sentence with the '
               'letter A.'}
2025-04-17 14:17:45 INFO Formatted evaluation instance 0
('Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural '
 'experiences and must-see attractions.')
2025-04-17 14:17:45 INFO Evaluating generation on mt_bench (model_attr={'model_type': 'chat', 'model_backend': 'openai', 'multi_turn': True}, generation_kwargs={'max_tokens': 4096, 'seed': 2023}, num_shots=0, len=80, num_instances=80, use_cache=False)
2025-04-17 14:34:48 WARNING Receive APIConnectionError: Connection error.,1 times, retrying...
2025-04-17 14:37:51 WARNING Receive APIConnectionError: Connection error.,2 times, retrying...
2025-04-17 14:40:54 WARNING Receive APIConnectionError: Connection error.,3 times, retrying...
2025-04-17 15:08:06 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 02174487368442938eab44a4b1ff29b46112b3edbb97f64a53f63 (request id: 20250417150804404582082VTHqXECC) (request id: 20250417150804321432299Xo0a0yKT) (request id: 202504171508042935492830Wm8n9Ys)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},1 times, retrying...
2025-04-17 15:08:08 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 02174487368609938eab44a4b1ff29b46112b3edbb97f642174b5 (request id: 2025041715080674658690h5ZbYCOJ) (request id: 20250417150805882391843N4CqKa99) (request id: 20250417150805855798874eFQwq6s6)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},2 times, retrying...
2025-04-17 15:09:02 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448737408406b3bec3035c23c28a9ed78d0631efe6ea1fae1 (request id: 20250417150900817013216WNkJMzsI) (request id: 20250417150900568771850YhrsAaH9) (request id: 20250417150900541376246Uvx51AoN)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},3 times, retrying...
2025-04-17 15:09:06 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448737448274e3ad01c392a13cd3d3a7f91c4d80e722d0889 (request id: 20250417150902372656955MzjD9Iu5) (request id: 20250417150902288742002nIGwy2Um) (request id: 20250417150902260725530lkaAhQ0x)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},4 times, retrying...
2025-04-17 15:09:08 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 02174487374675485767e7c1b7fac0507a87e172abc1cbe9b4fe4 (request id: 20250417150906728926624u9M8YRAA) (request id: 20250417150906643708284oTw7mJw7) (request id: 20250417150906616047958TEXZNmdQ)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},5 times, retrying...
2025-04-17 15:09:10 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448737483078fada59527794c4df4c247aab34e0cac96f9d1 (request id: 20250417150908283531163FDufheyZ) (request id: 20250417150908199739348sqMlK7pL) (request id: 20250417150908171321521YD0tYBel)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},6 times, retrying...
2025-04-17 15:09:12 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448737500366b3bec3035c23c28a9ed78d0631efe6ee4f6d8 (request id: 2025041715091012655171FtM0GAJz) (request id: 20250417150909764279411A0MsbvV1) (request id: 20250417150909736305206m4CHD9dI)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},7 times, retrying...
2025-04-17 15:09:19 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448737580654e3ad01c392a13cd3d3a7f91c4d80e72acafff (request id: 20250417150911583785430piIJrsgg) (request id: 2025041715091149944668224fS6i9U) (request id: 20250417150911469093534a5W4EtnQ)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},8 times, retrying...
2025-04-17 15:09:20 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448737603186b3bec3035c23c28a9ed78d0631efe6e904990 (request id: 20250417150920296368009juLpBBjj) (request id: 20250417150920213084526fGGVIF3q) (request id: 20250417150920185640886Gb359OrV)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},9 times, retrying...
2025-04-17 15:09:57 WARNING Receive BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448737965820620f76d79c3eae403de0b24cc40982a72a0da (request id: 20250417150921898591187UWCl9Vvc) (request id: 20250417150921814600426L7NHRCkF) (request id: 20250417150921786767590klwk2lkl)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}},10 times, retrying...
2025-04-17 15:10:09 INFO Finished at 65 instances after 50:19.
2025-04-17 15:10:09 WARNING Error occurred during evaluation. You can continue evaluation by loading the checkpoint: --continue_from evaluation_results/deepseek-v3-mt_bench-0shot-2025_04_17-14_17_35.json
2025-04-17 15:10:09 ERROR [evaluate] ConnectionError: BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448738048184e3ad01c392a13cd3d3a7f91c4d80e723e5f85 (request id: 20250417150958314873243MJt0wFLq) (request id: 20250417150958137473360tpihKeg4) (request id: 20250417150958109501039Ob6KIeYM)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}}
Cause: Your request was malformed or missing some required parameters, such as a token or an input.
Solution: The error message should advise you on the specific error made. Check the documentation for the specific API method you are calling and make sure you are sending valid and complete parameters. You may also need to check the encoding, format, or size of your request data.

Traceback (most recent call last):
  File "/home/dasoumao/LLMBox/utilization/model/model.py", line 353, in request
    response = self._chat_completions(
  File "/home/dasoumao/LLMBox/utilization/model/model.py", line 214, in wrapper
    results = func(*args, **kwargs)
  File "/home/dasoumao/LLMBox/utilization/model/openai_model.py", line 50, in _chat_completions
    results = openai.chat.completions.create(messages=messages, model=model, **kwargs)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 929, in create
    return self._post(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 1276, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 949, in request
    return self._request(
  File "/home/dasoumao/miniconda3/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py", line 1057, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448738048184e3ad01c392a13cd3d3a7f91c4d80e723e5f85 (request id: 20250417150958314873243MJt0wFLq) (request id: 20250417150958137473360tpihKeg4) (request id: 20250417150958109501039Ob6KIeYM)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dasoumao/LLMBox/utilization/utils/catch_error.py", line 40, in wrapper
    return func(*args, **kwargs)
  File "/home/dasoumao/LLMBox/utilization/evaluator.py", line 111, in evaluate
    batch_results = call_model(batch)
  File "/home/dasoumao/LLMBox/utilization/model/model_utils/batch_sampler.py", line 209, in call_model
    return self._forward_call(*args, **kwargs)  # type: ignore
  File "/home/dasoumao/LLMBox/utilization/model/model.py", line 305, in generation
    multi_turn_results = self.request(
  File "/home/dasoumao/LLMBox/utilization/model/model.py", line 382, in request
    raise ConnectionError(error_msg)
ConnectionError: BadRequestError: Error code: 400 - {'error': {'message': 'The parameter `max_tokens` specified in the request are not valid: integer above maximum value, expected a value <= 16384, but got 128000 instead. Request id: 0217448738048184e3ad01c392a13cd3d3a7f91c4d80e723e5f85 (request id: 20250417150958314873243MJt0wFLq) (request id: 20250417150958137473360tpihKeg4) (request id: 20250417150958109501039Ob6KIeYM)', 'type': 'BadRequest', 'param': 'max_tokens', 'code': 'InvalidParameter'}}
Cause: Your request was malformed or missing some required parameters, such as a token or an input.
Solution: The error message should advise you on the specific error made. Check the documentation for the specific API method you are calling and make sure you are sending valid and complete parameters. You may also need to check the encoding, format, or size of your request data.

